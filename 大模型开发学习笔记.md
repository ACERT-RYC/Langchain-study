 [toc] 

# 大模型开发学习笔记

## Day01--基本概念

### 1.RAG

> 检索增强生成，企业数据--向量数据库，增加大模型的能力，检索外部知识；RAG融合了信息检索和文本生成两种技术，先从大数据中检索信息，再基于这些信息生成文本。通过使用检索到的相关信息，RAG旨在提高文本生成的相关性、准确性和深度。RAG特别适用于需要广泛知识和深度理解的复杂查询，能够提供更丰富、更精确的回答。
>
> 核心流程：
>
> 1. 用户输入：（企业知识）
> 2. 检索：（用户问题--向量，去知识库检索最相关的文档）
> 3. 构造Prompt：拼接提示词，发给大模型
> 4. 大模型生成：降低幻觉
>
> 需要两个大模型：文本向量化模型（Embeding），推理模型（文本生成模型LLM）
>
> ![image-20250721103757797](D:\OneDrive\桌面\学习笔记\笔记图像保存\image-20250721103757797.png)
>
> 优点：数据可实时更新，适合动态知识
>
> 缺点：依赖搜索质量，查询不准会影响结果

### 2.微调

> 企业私有数据--LLM重新训练，增加大模型内化能力，让大模型本身就会
>
> 优点：适合特定领域知识增强，减少幻觉
>
> 缺点：训练成本高，难以频繁更新数据

### 3.三类基本业务架构

1. AI Embedded模式：正常的工作流程，在某一个流程中嵌入AI模型，主要是人工控制，AI辅助

![image-20250721092514569](D:\OneDrive\桌面\学习笔记\笔记图像保存\image-20250721092514569.png)

2. AI Copilot模式：用户和AI控制程度对半，用户和AI共同完成任务

![image-20250721092830216](D:\OneDrive\桌面\学习笔记\笔记图像保存\image-20250721092830216.png)

3. AI Agent模式：代理/智能体模式，用户控制程度较小，用户只需要提供基本要求，AI完成后续所有功能

### 4.向量

> 向量embedding：数字，相似度检索  后续语义计算
> 	文本，图片，语音，视频：高维，不可比较
> 	模型把要比较的内容部转换成【固定长度的向量】-----数学距离比较相似度
> 	相似度检索：余弦相似度
> 维向量：一串数字表达一个文本的属性，高维 低维
> 	简单模型：几十维表达基础语义
> 	复杂模型：BERT，768  1024+，捕捉更细粒度的语义和上下文关系
> 维度选择：任务需求和数据量

### 5.大模型特点和分类

> 特点：规模和参数数量大、适应性和灵活性强、广泛的数据集预训练、计算资源需求大
>
> 分类：大语言模型（LLM），多模态模型（计算机视觉模型、音频 处理模型）

### 6.大语言模型训练三阶段

#### **1. 预训练（Pre-training）**

**目标**：让模型学习语言的统计规律和通用知识。
**方法**：

- 使用**海量无标注文本**（如网页、书籍、维基百科等）。
- 通过**自监督学习**训练模型预测下一个词（如GPT的因果语言建模）。

**特点**：

- **规模驱动**：模型参数量大（通常数十亿至万亿），数据量可达TB级。
- **通用能力**：学会语法、事实知识、简单推理，但输出可能不连贯或不安全。
  **类比**：像“通读人类所有书籍”，建立基础世界观，但缺乏针对性。

>  **输出示例（未经微调的预训练模型）**：
> 用户提问：“如何做蛋糕？”
> 模型可能回答：“蛋糕是一种甜点，由面粉、糖和鸡蛋制成。第二次世界大战始于1939年…”（偏离主题、缺乏重点）

#### **2. 监督微调（SFT, Supervised Fine-Tuning）**

**目标**：教会模型遵循指令，生成有用、安全的回复。
**方法**：

- 使用**人工编写的优质问答数据**（如1万~10万条指令-回复对）。
- 在预训练模型上做**有监督训练**（输入是指令，输出是期望的回答）。

**特点**：

- **对齐指令**：模型学会理解问题意图、结构化输出。
- **初步可控**：减少无关内容，但可能仍存在偏见或逻辑错误。

> **SFT优化后的输出示例**：
> 用户提问：“如何做蛋糕？”
> 模型回答：“基础蛋糕做法：1. 混合面粉、糖、鸡蛋… 2. 烤箱预热至180°C…”（步骤清晰，但可能忽略安全提示）

#### **3. 基于人类反馈的强化学习（RLHF）**

**目标**：让模型输出更符合人类偏好（如**有帮助、无害、诚实**）。
**方法**：

1. **收集人类偏好数据**：
   - 让模型生成多个回答，人工选择最佳答案或排序。
2. **训练奖励模型（Reward Model）**：
   - 学习预测人类偏好的分数（例如：回答A比回答B好）。
3. **强化学习微调（如PPO算法）**：
   - 用奖励模型作为“裁判”，指导SFT模型优化策略，最大化奖励得分。

**关键作用**：

- **减少有害输出**：避免生成歧视性、危险内容。
- **提升有用性**：答案更简洁、逻辑清晰。
- **避免胡编乱造**：抑制模型“幻觉”（编造事实）。

> **RLHF优化后的输出示例**：
> 用户提问：“如何做蛋糕？”
> 模型回答：“基础蛋糕做法：1. 准备材料：面粉100g、糖80g… 👩🍳 **安全提示**：使用烤箱时请戴防烫手套。若对食材过敏，可替换为…”（有帮助+安全细节）

### 7.大语言模型的工作流程

> 1.分词化：将段落的句子分割为更小的分词（token）的过程，将一个句子分解成更小的、独立的部分可以帮助计算机理解句子的各个部分，以及它们在上下文中的作用，这对于进行大量上下文的分析尤其重要。
>
> 2.分词化的不同粒度
>
> - 一词粒度（Word-LevelTokenization）分词化，适用于大多数西方语言，如英语。
> - 字符粒度（Character-Level）分词化是中文最直接的分词方法，它是以单个汉字为
>   单位进行分词化。
> - 子词粒度（Subword-Level）分词化，它将单词分解成更小的单位，比如词根、词缀
>   等。这种方法对于处理新词（比如专有名词、网络用语等）特别有效，因为即使是新
>   词，它的组成部分（子词）很可能已经存在于词表中了。
>
> 每一个token都会通过预先设置好的词表，映射为一个tokenid，这是token的“身份证”，
> 一句话最终会被表示为一个元素为tokenid的列表，供计算机进行下一步处理。
>
> 3.大语言模型生成文本过程
>
> - 大语言模型的工作概括来说是根据给定的文本预测下一个token。对我们来说，看似像在对大模型提问，但实际上是给了大模型一串提示文本，让它可以对后续的文本进行推理。
> - 大模型的推理过程不是一步到位的，当大模型进行推理时，它会基于现有的token，根据概率最大原则预测出下一个最有可能的token，然后将该预测的token加入到输入序列中，并将更新后的输入序列继续输入大模型预测下一个token，这个过程叫做自回归。直到输出特殊token（如<EOS>，endof sentence，专门用来控制推理何时结束）或输出长度达到阈值。

### 8.卷积神经网络（CNN）

> CNN基本原理：卷积神经网络是一种深度学习网络，其基本原理是卷积运算，可以有效地处 理图像和视频数据。 
>
> CNN应用场景 ：积神经网络被广泛应用于图像分类、图像识别、视频分析等领域。 
>
> CNN的优势：与传统图像处理算法相比，卷积神经网络具有更强的自适应性和泛化能力， 能够处理更加复杂的图像任务。

### 9.自然语言处理（NLP）

> NLP是人工智能和计算机科学的一个重要分支，皆在是计算机能够理解和解释生成人类语言，它结合了计算机科学、语言学和数据科学的元素，用于解决与语言相关的各种问题。
>
> NLP的应用包括机器翻译、语音识别、情感分析、文本摘要、聊天机器人等。通过算法和大量的数据训练，NLP模型能够 从复杂的语言输入中提取有意义的信息，从而在自动化服务、数据分析、内容生成等多个领域发挥重要作用。

### 10.知识库

> 知识库就是存储知识和信息的系统，分为了传统知识库和AI知识库，AI知识库是与LLM（语言处理模型）相结合，AI系统更好地利用本地知识来响应查询和执行任务

### 11.Embeding

> 又称为嵌入、向量化、矢量化，将自然语言处理为模型可以读懂的数据格式
>
> 1.向量化表示：Embedding是将文本数据（如单词、短语或整个文档）转换为数值向量的过程。这些数值向量捕捉到了文本项的语义和语法特征，使得计算机能够处理文本数据。
>
> 2.维度降低：通过embedding，可以将每个文本项表示为一个较低维度的稠密向量，这些向量在较小的维度空间内保持了原始数据的重要特征。
>
> 3.语义关系：embedding向量能够编码语义信息，使得语义上相似的词汇在向量空间中彼此接近。这一特性使得embedding在信息检索、文本分类情感分析等任务中非常有效。

### 12.提示词工程（Prompt engineer）

> 定义：指的是在与人工智能系统交互时，如何精心设计和优化输入语句（prompts）的过程。这个过程关注于如何构造问题或命令，以从AI系统获取最有效和相关的回应。
>
> 目的与应用：主要目的是通过改进交互方式，提高与AI系统沟通的质量和效率。
>
> 关键性质：提示词工程重视语言的选择、上下文的应用，以及用户意图的明确表达。通过细致调整输入语句，可以优化AI的理解和响应，从而提高整体的交互体验

### 13.Finetuning(微调)

> 1.模型优化：微调是对预训练的人工智能模型进行进一步训练，以便它更好地适应特定的任务或数据集。
> 2.数据适应性：通过使用特定领域或任务的数据，微调调整模型的参数，使其更适合于该特定环境。
> 3.性能提升：微调的目的是提高模型在特定任务上的表现，比如提升精度、减少错误率或提高处理速度。

![image-20250722153159313](D:\OneDrive\桌面\学习笔记\笔记图像保存\image-20250722153159313.png)

### 14.AI Agent（AI代理人）

>  AI Agents是基于LLM的能够自主理解、自主规划决策、执行复杂任务的智能体。是通向AGI（通用人工智能）的工具。
>
>  AI Agents是设计用来感知环境、做出决策并自主行动以实现特定目标的软件程序或系统。
>  它们通过内部模型来考虑除当前输入之外的一些上下文，从而做出更为明智的决策
>
>  这些智能体可以像规划者一样，设定特定的目标或目的，并在当前状态、所需达到的目标以及达到这些目标的一系列行动之间进行选择
>
>  AI Agents也包括学习型智能体，它们能够根据接收到的数据和反馈适应和改进其决策制定。

Agents流程图

![image-20250721145600956](D:\OneDrive\桌面\学习笔记\笔记图像保存\image-20250721145600956.png)

> 1. 规划（Planning）：智能体会把大型任务分解为子任务，并规划执行任务的流程；智能体会对任务执行的过程进行思考和反思，从而决定是继续执行任务，或判断任务完结并终止运行。
> 2. 记忆（Memory）：短期记忆，是指在执行任务的过程中的上下文，会在子任务的执行过程产生和暂存，在任务完结后被清空。长期记忆是长时间保留的信息，一般是指外部知识库，通常用向量数据库来存储和检索。
> 3. 工具使用（TooIs）：为智能体配备工具API，比如：计算器、搜索工具、代码执行器、数据库查询工具等。有了这些工具API，智能体就可以是物理世界交互，解决实际的问题。
> 4. 执行（Action）：根据规划和记忆来实施具体行动，这可能会涉及到与外部世界的互动或通过工具来完成任务。

























